#######################################
#	DISABLE NULL ON JSON
#######################################
spring.jackson.default-property-inclusion = NON_NULL 

server.port=9091
spring.application.name=srv-query-ms
server.servlet.context-path=/

####### APPLICATION MONITORING ################
info.app.name=EDS SRV Query Microservice
info.app.description=EDS SRV Query Microservice for FSE.
info.app.version=1.0.0

management.server.port=9091
management.endpoints.web.base-path=/
management.endpoints.web.path-mapping.live=status
management.endpoints.web.path-mapping.health=health-ready
management.endpoint.metrics.enabled=true
management.endpoint.prometheus.enabled=true
management.endpoints.web.path-mapping.prometheus=metrics
management.endpoints.web.path-mapping.metrics=actuator
management.endpoints.web.exposure.include=health,metrics,prometheus,live,ready,env,info
management.health.db.enabled=true
management.endpoint.health.show-details=always
####### APPLICATION MONITORING ################

####### LOGGING OUTPUT FORMAT ############
# Must be one of console or json
#######################################
log.output.format=console

#######################################
#  KAFKA 
#######################################
####KAFKA CONNECTION SETTINGS ##########
kafka.bootstrap-servers=${KAFKA_HOST}:${KAFKA_PORT1},${KAFKA_HOST}:${KAFKA_PORT2},${KAFKA_HOST}:${KAFKA_PORT3}
spring.sleuth.messaging.kafka.enabled=false
kafka.properties.security.protocol=SASL_SSL
kafka.properties.sasl.mechanism=SCRAM-SHA-256
kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username='${kafka_user-it-dgc-certificate-service}' password='${kafka_password-it-dgc-certificate-service}';
kafka.properties.ssl.truststore.location=/config/resources/security/truststore.jks
kafka.properties.ssl.truststore.password=${TRUST_JKS_PASSWORD}
kafka.enablessl=true

####### KAFKA PRODUCER SETTINGS ################
kafka.producer.client-id=springboot-srv-query
kafka.producer.retries=5 
kafka.producer.key-serializer= org.apache.kafka.common.serialization.StringSerializer
kafka.producer.value-serializer= org.apache.kafka.common.serialization.StringSerializer
kafka.producer.transactional.id=srvquery.tx.
kafka.producer.enable.idempotence=true
kafka.producer.ack=all
 
#######KAFKA CONSUMER SETTING################
kafka.consumer.client-id=springboot-srv-query

kafka.consumer.group-id=srv-query
kafka.consumer.bootstrap-servers=${KAFKA_HOST}:${KAFKA_PORT1},${KAFKA_HOST}:${KAFKA_PORT2},${KAFKA_HOST}:${KAFKA_PORT3}
kafka.consumer.key-deserializer= org.apache.kafka.common.serialization.StringDeserializer
kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
kafka.consumer.auto-offset-reset=earliest
kafka.consumer.isolation.level=read_committed
kafka.consumer.auto-commit=false

###### KAFKA TOPIC ##########
# Consumer
kafka.query.deadletter.topic=EDS-SRV-QUERY-DEADLETTER
# Producer
kafka.create-elasticsearch.topic=CREATE-ELASTICSEARCH-TOPIC
event.topic.auto.start=true

####### KAFKA DEAD LETTER #####################
kafka.consumer.dead-letter-exc={'java.lang.NullPointerException', 'it.finanze.sanita.fse2.ms.srvquery.exceptions.BusinessException'}


#######################################
#  OPENAPI 
#######################################
springdoc.swagger-ui.path=/openapi/ui

docs.info.contact.name=Mario Rossi
docs.info.contact.mail=mariorossi@ibm.com
docs.info.contact.url=www.example.com
docs.info.termsOfService=www.terms.com
docs.info.summary=Query Module for documents towards EDS
docs.info.description=The Query Module for EDS 
docs.info.api-id=1
docs.info.title=EDS Query Microservice
validation.file-max-size=1000

#######################################
#  FHIR CFG 
#######################################
fhir-server-url=http://localhost:8080/fhir